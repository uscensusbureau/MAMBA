projectPath = /path/to/your/project ##the path for our output files
data1_name = data1  ###First dataset name
data2_name = data2  ###Second dataset name.
sql_flavor = postgres ###what flavor of sql are you using? current options: sqlite or postgres.  if using postgres, add in db_user, db_port, db_password, db_schema, and db_host as entries
db_name = postgres ###database name
db_user = postgres
db_port = 5432
db_host = localhost
db_schema = r10000
debugmode = False ###run in debug mode?
block_file_name = block_names.csv ###The file (including .csv ending) where the names of the blocking variables live
database_creation_mode = create ###if you already have data, enter something other than create here.
create_db_chunksize = 100000  ###the size of the chunks we want to read in
training_data_name = training_data  ###name of the training data.csv file.  don't include .csv ending
rf_jobs = 1  ###Number of jobs in the random forest
clerical_review_candidates = False  ##do we want to generate clerical review candidates
###Two values: variable: the name of the variable from your mamba_variable_types that you want to filter clerical review candidates on
###NOTE: if you're using a fuzzy variable, have it be the pattern {variable name}_{fuzzy comparator}.  So "name_jaro" to look at the jaro score of the name.
###If you are using the predicted probability from a model, make this "predicted_probability"
###value: in double quotes, the lower value you want to consider.
clerical_review_threshold = {"variable":"predicted_probability", "value":".3"}
###this fits after an 'and' statement so don't include the first and.
###you can put in 1=1 here to just select everything whether it was matched or not
custom_selection_statement = False
match_threshold = .5  ##what is the match threshold you want to look at
chatty_logger = True  ##if on, logger logs after every block
log_file_name = mamba_test_log ##the anme of your log file
numWorkers = 3 ##number of workers in the Runner object
prediction = True ##are we generating match predictions?
scoringcriteria = accuracy
ignore_duplicate_ids = False ###are we trying to depulicate the same dataset? This assumes the IDs are the same on each set (so a record in A has the same record in B)
use_logit = True ####Use the logit.  If you do this, scoring will be converted to accuracy (only built-in feature)
date_format = %Y-%m-%d   ###format for any dates
stem_phrase = False ###Use the stemming/phrasing feature?
parse_address = False   ###are we using the address parsing?
address_column_data1_test = address_unparsed   ###name of address column needed parsed in the first dataset
address_column_data2_test = address_raw ###name of address column needed parsed in the second dataset
use_remaining_parsed_address = False ##are we using thee leftover address parsing info to match?
standardize_addresses = False ###do you want to standarize addresses?
####if for a dataset you don't want to standardize for a particular dataset, don't include a json entry
address_to_standardize = {} 
###Are we running a custom model?
use_custom_model = False
###What imputation model are we using: Imputation = impute values using an iterative imputer,Nnominal means cut fuzzy vars
imputation_method = Nominal
###use the built-in mamba models?
use_mamba_models = True
##Are you using a previously used model? include the '.joblib' file suffix. enter 'False' otherwise
saved_model = newmod.joblib
##If you have a new model, do you want to save it? If so, enter the filename (including the .joblib ending)
###Note.  If use_saved_model has a .joblib ending, this will be ignored.
saved_model_target = newmod.joblib
###Do you want to run in recursive feature elimination mode?
feature_elimination_mode = True
###Do you want to run a pre-filter for your models?
use_variable_filter = True
###If use_variable_filter is True, details here.  See readme for available options
variable_filter_info = {"variable_name": "first_name", "fuzzy_name": "jaro", "test":">", "filter_value":".65"}
# What mode are you running -- can be 'deduplication', in which case identical IDs will be ignored, or any other statement.
mode = False 
# Do you want a global filter statement to apply to any possible match pair (e.g. must have a jaro score above .5)
global_filter_statement = False
# Do you want to use a random forest? (note: will be ignored if saved_model has a .joblib ending)
use_rf = True
# Do you want to use a SVN classifier? (note: will be ignored if saved_model has a .joblib ending)
use_svn = False
# Do you want to use a AdaBoost classifier? (note: will be ignored if saved_model has a .joblib ending)
use_ada = False
